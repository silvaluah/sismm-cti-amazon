{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "803fee5f",
   "metadata": {},
   "source": [
    "# 3 - Análise Exploratória da Fonte Espacenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff945c0",
   "metadata": {},
   "source": [
    "# 3.1: Carregando e Explorando os Dados da Espacenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3880eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"--- Célula 1: Iniciando a análise exploratória da fonte Espacenet ---\")\n",
    "\n",
    "# Define o caminho para a pasta de dados.\n",
    "caminho_pasta = Path('../../data/raw/espacenet_input')\n",
    "\n",
    "try:\n",
    "    # Encontra todos os arquivos CSV na pasta\n",
    "    arquivos_csv = list(caminho_pasta.glob('*.csv'))\n",
    "    \n",
    "    if not arquivos_csv:\n",
    "        print(f\"ERRO: Nenhum arquivo CSV encontrado na pasta '{caminho_pasta.resolve()}'\")\n",
    "    else:\n",
    "        print(f\"Encontrados {len(arquivos_csv)} arquivos CSV. Carregando e consolidando...\")\n",
    "        \n",
    "        # CORREÇÃO: Trocando o separador para ponto e vírgula (';')\n",
    "        lista_dfs = [pd.read_csv(f, sep=';') for f in arquivos_csv]\n",
    "        \n",
    "        # Concatena todos os DataFrames em um só\n",
    "        df_espacenet = pd.concat(lista_dfs, ignore_index=True)\n",
    "\n",
    "        print(f\"\\nArquivos consolidados com sucesso! Total de {len(df_espacenet)} registros.\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 1. Informações Gerais\n",
    "        print(\"\\n[1] INFORMAÇÕES GERAIS DO DATAFRAME:\")\n",
    "        df_espacenet.info()\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # 2. Amostra dos Dados\n",
    "        print(\"\\n[2] AMOSTRA DOS DADOS (5 PRIMEIRAS LINHAS):\")\n",
    "        display(df_espacenet.head())\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 3. Verificação de Valores Nulos\n",
    "        print(\"\\n[3] CONTAGEM DE VALORES NULOS POR COLUNA:\")\n",
    "        valores_nulos = df_espacenet.isnull().sum()\n",
    "        print(valores_nulos[valores_nulos > 0].sort_values(ascending=False))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERRO: Pasta não encontrada em '{caminho_pasta.resolve()}'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado ao carregar os arquivos: {e}\")\n",
    "    print(\"Dica: Se o erro persistir, pode ser um problema de codificação (tente adicionar encoding='latin-1').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc0d01",
   "metadata": {},
   "source": [
    "# 3.2: Limpeza Inicial do DataFrame Espacenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e67366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "print(\"--- Célula 2: Limpeza estrutural do DataFrame da Espacenet ---\")\n",
    "\n",
    "try:\n",
    "    df_espacenet_limpo = df_espacenet.copy()\n",
    "\n",
    "    # --- 1. Remover as colunas 'Unnamed' ---\n",
    "    colunas_unnamed = [col for col in df_espacenet_limpo.columns if 'unnamed' in col.lower()]\n",
    "    df_espacenet_limpo = df_espacenet_limpo.drop(columns=colunas_unnamed)\n",
    "    print(f\"[1] Removidas {len(colunas_unnamed)} colunas 'Unnamed'.\")\n",
    "\n",
    "    # --- 2. Padronizar os nomes das colunas restantes ---\n",
    "    print(\"\\n[2] Padronizando nomes das colunas...\")\n",
    "    print(\"   Colunas ANTES:\", df_espacenet_limpo.columns.tolist())\n",
    "    \n",
    "    novas_colunas = []\n",
    "    for col in df_espacenet_limpo.columns:\n",
    "        col = str(col)\n",
    "        col_normalizada = unicodedata.normalize('NFKD', col).encode('ascii', 'ignore').decode('utf-8')\n",
    "        col_minuscula = col_normalizada.lower()\n",
    "        col_com_underscore = col_minuscula.replace(' ', '_').replace('-', '_')\n",
    "        col_final = re.sub(r'[^a-z0-9_]', '', col_com_underscore)\n",
    "        novas_colunas.append(col_final)\n",
    "    df_espacenet_limpo.columns = novas_colunas\n",
    "    \n",
    "    print(\"   Colunas DEPOIS:\", df_espacenet_limpo.columns.tolist())\n",
    "\n",
    "    # --- 3. Tratamento básico de nulos para evitar erros futuros ---\n",
    "    # Converte colunas que serão multivaloradas para string e preenche nulos\n",
    "    colunas_para_tratar = ['inventors', 'applicants', 'ipc', 'cpc', 'publication_number', 'publication_date']\n",
    "    for col in colunas_para_tratar:\n",
    "        if col in df_espacenet_limpo.columns:\n",
    "            df_espacenet_limpo[col] = df_espacenet_limpo[col].astype(str).fillna('NAO INFORMADO')\n",
    "\n",
    "    print(\"\\n[3] Limpeza básica de nulos concluída.\")\n",
    "    \n",
    "    print(\"\\n--- Limpeza inicial finalizada! ---\")\n",
    "    print(\"DataFrame 'df_espacenet_limpo' foi criado.\")\n",
    "    display(df_espacenet_limpo.head())\n",
    "    \n",
    "except NameError:\n",
    "    print(\"ERRO: O DataFrame 'df_espacenet' não foi encontrado. Execute a Célula 1 primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07956a4e",
   "metadata": {},
   "source": [
    "# 3.3: Criando a Dimensão de Parties (Inventores e Requerentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Célula 3: Criando a dimensão de Parties e a tabela ponte ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Selecionar colunas de interesse e garantir que sejam strings\n",
    "    df_parties_trab = df_espacenet_limpo[['publication_number', 'inventors', 'applicants']].copy()\n",
    "    \n",
    "    # 2. Despivôar (unpivot/melt) as colunas de inventors e applicants\n",
    "    # para ter uma única coluna com o nome e outra com o \"papel\" (role)\n",
    "    df_melted = df_parties_trab.melt(\n",
    "        id_vars=['publication_number'],\n",
    "        value_vars=['inventors', 'applicants'],\n",
    "        var_name='role',\n",
    "        value_name='party_string'\n",
    "    )\n",
    "    \n",
    "    # Remove linhas onde não há informação de party\n",
    "    df_melted = df_melted[df_melted['party_string'] != 'NAO INFORMADO']\n",
    "\n",
    "    # 3. Separar os múltiplos nomes (que estão separados por vírgula) e explodir\n",
    "    df_melted['party_string'] = df_melted['party_string'].str.split(',')\n",
    "    df_explodido = df_melted.explode('party_string')\n",
    "    \n",
    "    # Limpa espaços extras de cada nome\n",
    "    df_explodido['party_string'] = df_explodido['party_string'].str.strip()\n",
    "    df_explodido = df_explodido[df_explodido['party_string'] != '']\n",
    "\n",
    "    # 4. Criar a tabela de dimensão com parties únicas\n",
    "    # Usamos o nome limpo como a entidade única para a dimensão\n",
    "    dim_parties = pd.DataFrame(df_explodido['party_string'].unique(), columns=['party_nome'])\n",
    "    dim_parties.reset_index(inplace=True)\n",
    "    dim_parties.rename(columns={'index': 'party_id'}, inplace=True)\n",
    "\n",
    "    print(\"\\n[1] Tabela 'dim_parties' criada:\")\n",
    "    display(dim_parties.head())\n",
    "\n",
    "    # 5. Criar a tabela ponte\n",
    "    pon_patente_party = pd.merge(\n",
    "        df_explodido,\n",
    "        dim_parties,\n",
    "        left_on='party_string',\n",
    "        right_on='party_nome',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # A tabela ponte agora pode ter o papel (inventor/applicant)\n",
    "    # Primeiro, vamos simplificar o nome do papel\n",
    "    pon_patente_party['role'] = pon_patente_party['role'].str.replace('s', '') # inventors -> inventor\n",
    "    \n",
    "    # Seleciona e agrupa para garantir uma relação única por papel\n",
    "    pon_patente_party = pon_patente_party[['publication_number', 'party_id', 'role']].drop_duplicates()\n",
    "\n",
    "    print(\"\\n[2] Tabela 'pon_patente_party' criada:\")\n",
    "    display(pon_patente_party.head())\n",
    "\n",
    "except NameError:\n",
    "    print(\"ERRO: O DataFrame 'df_espacenet_limpo' não foi encontrado. Execute a Célula 2 primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d509145",
   "metadata": {},
   "source": [
    "# 3.4: Criando a Dimensão de Países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009fbeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Célula 4: Criando a dimensão de Países e a tabela ponte ---\")\n",
    "\n",
    "# Dicionário de códigos de país, extraído do seu script original\n",
    "COUNTRY_CODES = {\n",
    "    'AR': 'Argentina', 'AT': 'Áustria', 'AU': 'Austrália', 'BA': 'Bósnia e Herzegovina', 'BE': 'Bélgica', \n",
    "    'BG': 'Bulgária', 'BR': 'Brasil', 'CA': 'Canadá', 'CH': 'Suíça', 'CN': 'China', \n",
    "    'CS': 'Checoeslováquia (até 1993)', 'CU': 'Cuba', 'CY': 'Chipre', 'CZ': 'República Checa', \n",
    "    'DD': 'Alemanha Oriental', 'DE': 'Alemanha', 'DK': 'Dinamarca', 'DZ': 'Argélia', \n",
    "    'EA': 'Organização Euroasiática de Patentes', 'EE': 'Estónia', 'EG': 'Egipto', \n",
    "    'EP': 'Organização Europeia de Patentes (OPE/EPO)', 'ES': 'Espanha', 'FI': 'Finlândia', \n",
    "    'FR': 'França', 'GB': 'Reino Unido', 'GR': 'Grécia', 'HK': 'Hong Kong', 'HU': 'Hungria', \n",
    "    'IE': 'Irlanda', 'IL': 'Israel', 'IN': 'India', 'IT': 'Itália', 'JP': 'Japão', 'KE': 'Quénia', \n",
    "    'KR': 'Coreia do Sul', 'LU': 'Luxemburgo', 'LV': 'Letónia', 'MC': 'Mónaco', 'MD': 'República da Moldávia', \n",
    "    'MN': 'Mongólia', 'MT': 'Malta', 'MW': 'Malawi', 'MX': 'México', 'MY': 'Malásia', 'NC': 'Nova Caledónia', \n",
    "    'NL': 'Holanda', 'NO': 'Noruega', 'NZ': 'Nova Zelândia', \n",
    "    'OA': 'Organização Africana da Propriedade Intelectual (OAPI)', 'PH': 'Filipinas', 'PL': 'Polónia', \n",
    "    'PT': 'Portugal', 'RO': 'Roménia', 'RU': 'Federação Russa', 'SE': 'Suécia', 'SG': 'Singapura', \n",
    "    'SI': 'Eslovénia', 'SK': 'Eslováquia', 'SU': 'União Soviética', 'TJ': 'Tadjiquistão', 'TR': 'Turquia', \n",
    "    'TT': 'Trindade e Tobago', 'TW': 'Taiwan', 'US': 'Estados Unidos da América', 'VN': 'Vietname', \n",
    "    'WO': 'Organização Mundial da Propriedade Intelectual (OMPI/WIPO)', 'YU': 'Jugoslávia', \n",
    "    'ZA': 'África do Sul', 'ZM': 'Zâmbia', 'ZW': 'Zimbabwe'\n",
    "}\n",
    "\n",
    "try:\n",
    "    # --- 1. Criar a tabela dim_country ---\n",
    "    dim_country = pd.DataFrame(COUNTRY_CODES.items(), columns=['country_code', 'country_name'])\n",
    "    dim_country.reset_index(inplace=True)\n",
    "    dim_country.rename(columns={'index': 'country_id'}, inplace=True)\n",
    "    print(\"\\n[1] Tabela 'dim_country' criada:\")\n",
    "    display(dim_country.head())\n",
    "\n",
    "    # --- 2. Extrair códigos de país de múltiplas fontes ---\n",
    "    # Fonte 1: Número da Publicação\n",
    "    df_from_pub = df_espacenet_limpo[['publication_number']].copy()\n",
    "    df_from_pub['country_code'] = df_from_pub['publication_number'].str[:2]\n",
    "    df_from_pub['origin'] = 'Publication'\n",
    "    \n",
    "    # Fonte 2 e 3: Requerentes (Applicants) e Inventores (Inventors)\n",
    "    df_from_parties = df_espacenet_limpo[['publication_number', 'inventors', 'applicants']].copy()\n",
    "    df_melted_parties = df_from_parties.melt(id_vars=['publication_number'], value_vars=['inventors', 'applicants'], var_name='origin')\n",
    "    df_melted_parties['value'] = df_melted_parties['value'].str.split(',')\n",
    "    df_exploded_parties = df_melted_parties.explode('value')\n",
    "    # Extrai o código de 2 letras entre colchetes\n",
    "    df_exploded_parties['country_code'] = df_exploded_parties['value'].str.extract(r'\\[([A-Z]{2})\\]')\n",
    "    df_exploded_parties['origin'] = df_exploded_parties['origin'].str.replace('s', '').str.capitalize()\n",
    "    \n",
    "    # --- 3. Consolidar todas as fontes e criar a tabela ponte ---\n",
    "    # Juntamos os códigos extraídos das publicações e das parties\n",
    "    df_relations = pd.concat([\n",
    "        df_from_pub[['publication_number', 'country_code', 'origin']],\n",
    "        df_exploded_parties[['publication_number', 'country_code', 'origin']]\n",
    "    ]).dropna(subset=['country_code'])\n",
    "\n",
    "    # Filtra apenas relações com códigos de país que existem em nosso dicionário\n",
    "    df_relations = df_relations[df_relations['country_code'].isin(COUNTRY_CODES.keys())]\n",
    "\n",
    "    # Junta com a dim_country para obter o country_id\n",
    "    pon_patente_country = pd.merge(\n",
    "        df_relations,\n",
    "        dim_country,\n",
    "        on='country_code',\n",
    "        how='left'\n",
    "    )\n",
    "    # Seleciona as colunas finais e remove duplicatas\n",
    "    pon_patente_country = pon_patente_country[['publication_number', 'country_id', 'origin']].drop_duplicates()\n",
    "\n",
    "    print(\"\\n[2] Tabela 'pon_patente_country' criada:\")\n",
    "    display(pon_patente_country.head())\n",
    "\n",
    "except NameError:\n",
    "    print(\"ERRO: O DataFrame 'df_espacenet_limpo' não foi encontrado. Execute a Célula 2 primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f19f3a",
   "metadata": {},
   "source": [
    "# 3.5: Criando a Dimensão de Classificação IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Célula 5: Criando a dimensão de Classificação IPC e a tabela ponte ---\")\n",
    "\n",
    "# --- 1. Função Auxiliar de Limpeza (adaptada do seu script) ---\n",
    "def clean_ipc_code(ipc_code_str):\n",
    "    \"\"\"\n",
    "    Padroniza um código IPC para um formato consistente, removendo espaços e hífens.\n",
    "    \"\"\"\n",
    "    if pd.isna(ipc_code_str) or not isinstance(ipc_code_str, str):\n",
    "        return None\n",
    "    # Converte para maiúsculas e remove espaços/hífens\n",
    "    return ipc_code_str.upper().strip().replace('-', '').replace(' ', '')\n",
    "\n",
    "try:\n",
    "    # --- 2. Preparar e explodir os dados de IPC ---\n",
    "    df_ipc_trab = df_espacenet_limpo[['publication_number', 'ipc']].copy()\n",
    "    df_ipc_trab = df_ipc_trab[df_ipc_trab['ipc'] != 'NAO INFORMADO']\n",
    "\n",
    "    # Divide os códigos IPC (separados por vírgula) em listas\n",
    "    df_ipc_trab['ipc'] = df_ipc_trab['ipc'].str.split(',')\n",
    "    df_ipc_explodido = df_ipc_trab.explode('ipc')\n",
    "    \n",
    "    # Aplica a função de limpeza para padronizar os códigos\n",
    "    df_ipc_explodido['ipc_code_normalizado'] = df_ipc_explodido['ipc'].apply(clean_ipc_code)\n",
    "    df_ipc_explodido.dropna(subset=['ipc_code_normalizado'], inplace=True)\n",
    "    df_ipc_explodido = df_ipc_explodido[df_ipc_explodido['ipc_code_normalizado'] != '']\n",
    "    \n",
    "    # --- 3. Criar a tabela de dimensão IPC ---\n",
    "    # A dimensão será baseada nos códigos normalizados únicos\n",
    "    dim_ipc = pd.DataFrame(df_ipc_explodido['ipc_code_normalizado'].unique(), columns=['ipc_code'])\n",
    "    dim_ipc.reset_index(inplace=True)\n",
    "    dim_ipc.rename(columns={'index': 'ipc_id'}, inplace=True)\n",
    "\n",
    "    print(\"\\n[1] Tabela 'dim_ipc' criada:\")\n",
    "    display(dim_ipc.head())\n",
    "\n",
    "    # --- 4. Criar a tabela ponte Patente-IPC ---\n",
    "    pon_patente_ipc = pd.merge(\n",
    "        df_ipc_explodido,\n",
    "        dim_ipc,\n",
    "        left_on='ipc_code_normalizado',\n",
    "        right_on='ipc_code',\n",
    "        how='left'\n",
    "    )\n",
    "    pon_patente_ipc = pon_patente_ipc[['publication_number', 'ipc_id']].drop_duplicates()\n",
    "\n",
    "    print(\"\\n[2] Tabela 'pon_patente_ipc' criada:\")\n",
    "    display(pon_patente_ipc.head())\n",
    "\n",
    "except NameError:\n",
    "    print(\"ERRO: O DataFrame 'df_espacenet_limpo' não foi encontrado. Execute a Célula 2 primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d9d89",
   "metadata": {},
   "source": [
    "# 3.6:  Carregando seu Levantamento Manual de Espécies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6af1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Célula 6: Carregando o arquivo de levantamento manual de espécies da Espacenet ---\")\n",
    "\n",
    "# Define o caminho para o seu novo arquivo\n",
    "caminho_manual = Path('../../data/raw/espacenet_resumo_plantas.csv')\n",
    "\n",
    "try:\n",
    "    # Carrega o arquivo. Vamos assumir o separador padrão (vírgula)\n",
    "    df_espacenet_especies_manual = pd.read_csv(caminho_manual)\n",
    "    \n",
    "    print(f\"\\nArquivo '{caminho_manual.name}' carregado com sucesso!\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 1. Informações Gerais\n",
    "    print(\"\\n[1] INFORMAÇÕES GERAIS DO DATAFRAME MANUAL:\")\n",
    "    df_espacenet_especies_manual.info()\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Amostra dos Dados\n",
    "    print(\"\\n[2] AMOSTRA DOS DADOS MANUAIS (5 PRIMEIRAS LINHAS):\")\n",
    "    display(df_espacenet_especies_manual.head())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERRO: Arquivo não encontrado em '{caminho_manual.resolve()}'\")\n",
    "    print(\"Por favor, verifique se o nome do arquivo e o caminho estão corretos.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado ao carregar o arquivo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab5a1f",
   "metadata": {},
   "source": [
    "# 3.7: Mapeamento Automático de Espécies (para Comparação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1edaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Célula 7: Realizando o mapeamento automático de espécies para validação ---\n",
      "[0] DataFrame 'df_termos' da CNCFlora carregado para consulta.\n",
      "[1] DataFrame da Espacenet enriquecido com os resumos.\n",
      "[2] Dicionário de busca com 1980 nomes de plantas foi criado.\n",
      "[3] Busca automática por espécies concluída.\n",
      "\n",
      "--- Tabela de Comparação (Manual vs. Automático) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>planta_levantada_manualmente</th>\n",
       "      <th>especies_encontradas_auto</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US2018206423A1</td>\n",
       "      <td>Salvinia sprucei</td>\n",
       "      <td>[]</td>\n",
       "      <td>MARINE BIOMASS REACTOR AND METHODS RELATED THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US2010292280A1</td>\n",
       "      <td>Petrea insignis</td>\n",
       "      <td>[]</td>\n",
       "      <td>ANTI-PYRETIC VASODILATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JP2001122732A</td>\n",
       "      <td>Manilkara excelsa</td>\n",
       "      <td>[]</td>\n",
       "      <td>COSMETIC COMPOSITION CONTAINING MOISTURIZING P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JPH10139680A</td>\n",
       "      <td>Euxylophora paraensis</td>\n",
       "      <td>[]</td>\n",
       "      <td>ANTIANDROGEN AGENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JP2001055318A</td>\n",
       "      <td>Euxylophora paraensis</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPOSITION FOR ORAL CAVITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US2009223000A1</td>\n",
       "      <td>Euxylophora paraensis</td>\n",
       "      <td>[Euxylophora paraensis]</td>\n",
       "      <td>Manufacturing process of vegetable colorant ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US2020390841A1</td>\n",
       "      <td>Vismia cauliflora, Vismia cavalcantei,  Calyco...</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPOSITIONS AND METHODS FOR TREATING WOUNDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US5177306A</td>\n",
       "      <td>Rhabdodendron macrophyllum</td>\n",
       "      <td>[]</td>\n",
       "      <td>ABIENOL-PRODUCING SOMACLONAL VARIANTS OF NICOT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JP2012126715A</td>\n",
       "      <td>Passiflora riparia</td>\n",
       "      <td>[]</td>\n",
       "      <td>MEDICINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>JP2016183142A</td>\n",
       "      <td>Passiflora riparia</td>\n",
       "      <td>[]</td>\n",
       "      <td>LIPOSOME FORMULATION OF POLYPHENOL AND PRODUCT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publication_number                       planta_levantada_manualmente  \\\n",
       "0      US2018206423A1                                   Salvinia sprucei   \n",
       "2      US2010292280A1                                    Petrea insignis   \n",
       "3       JP2001122732A                                  Manilkara excelsa   \n",
       "6        JPH10139680A                              Euxylophora paraensis   \n",
       "7       JP2001055318A                              Euxylophora paraensis   \n",
       "8      US2009223000A1                              Euxylophora paraensis   \n",
       "10     US2020390841A1  Vismia cauliflora, Vismia cavalcantei,  Calyco...   \n",
       "11         US5177306A                         Rhabdodendron macrophyllum   \n",
       "14      JP2012126715A                                 Passiflora riparia   \n",
       "20      JP2016183142A                                 Passiflora riparia   \n",
       "\n",
       "   especies_encontradas_auto  \\\n",
       "0                         []   \n",
       "2                         []   \n",
       "3                         []   \n",
       "6                         []   \n",
       "7                         []   \n",
       "8    [Euxylophora paraensis]   \n",
       "10                        []   \n",
       "11                        []   \n",
       "14                        []   \n",
       "20                        []   \n",
       "\n",
       "                                                title  \n",
       "0   MARINE BIOMASS REACTOR AND METHODS RELATED THE...  \n",
       "2                           ANTI-PYRETIC VASODILATORS  \n",
       "3   COSMETIC COMPOSITION CONTAINING MOISTURIZING P...  \n",
       "6                                  ANTIANDROGEN AGENT  \n",
       "7                         COMPOSITION FOR ORAL CAVITY  \n",
       "8   Manufacturing process of vegetable colorant ex...  \n",
       "10       COMPOSITIONS AND METHODS FOR TREATING WOUNDS  \n",
       "11  ABIENOL-PRODUCING SOMACLONAL VARIANTS OF NICOT...  \n",
       "14                                           MEDICINE  \n",
       "20  LIPOSOME FORMULATION OF POLYPHENOL AND PRODUCT...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(\"--- Célula 7: Realizando o mapeamento automático de espécies para validação ---\")\n",
    "\n",
    "try:\n",
    "    # --- NOVO: Carregar o df_termos necessário para o dicionário de busca ---\n",
    "    caminho_txt_cncflora = Path('../../data/raw/cncflora/termos_plantas.txt')\n",
    "    df_termos = pd.read_csv(\n",
    "        caminho_txt_cncflora, \n",
    "        sep=',', \n",
    "        header=None, \n",
    "        names=['nome_cientifico_completo', 'grupo_taxonomico']\n",
    "    )\n",
    "    print(\"[0] DataFrame 'df_termos' da CNCFlora carregado para consulta.\")\n",
    "    # --- Fim da adição ---\n",
    "\n",
    "    # Padronizar as colunas do arquivo manual primeiro\n",
    "    df_manual_padronizado = df_espacenet_especies_manual.copy()\n",
    "    df_manual_padronizado.columns = [\n",
    "        'publication_number', \n",
    "        'abstract', \n",
    "        'planta_levantada_manualmente'\n",
    "    ]\n",
    "    \n",
    "    # --- 1. Enriquecer o df_espacenet_limpo com os resumos do arquivo manual ---\n",
    "    df_resumos = df_manual_padronizado[['publication_number', 'abstract']].copy()\n",
    "    \n",
    "    df_espacenet_enriquecido = pd.merge(\n",
    "        df_espacenet_limpo,\n",
    "        df_resumos.drop_duplicates(subset=['publication_number']),\n",
    "        on='publication_number',\n",
    "        how='left'\n",
    "    )\n",
    "    df_espacenet_enriquecido['abstract'] = df_espacenet_enriquecido['abstract'].fillna('NAO INFORMADO')\n",
    "    print(\"[1] DataFrame da Espacenet enriquecido com os resumos.\")\n",
    "\n",
    "    # --- 2. Criar o dicionário de busca unificado ---\n",
    "    plantas_cncflora = df_termos['nome_cientifico_completo'].dropna().unique()\n",
    "    plantas_manual_espacenet = df_manual_padronizado['planta_levantada_manualmente'].dropna().unique()\n",
    "    \n",
    "    lista_de_plantas_mestre = pd.concat([\n",
    "        pd.Series(plantas_cncflora),\n",
    "        pd.Series(plantas_manual_espacenet)\n",
    "    ]).dropna().unique().tolist()\n",
    "    \n",
    "    regex_pattern = r'\\b(' + '|'.join(re.escape(nome) for nome in lista_de_plantas_mestre) + r')\\b'\n",
    "    print(f\"[2] Dicionário de busca com {len(lista_de_plantas_mestre)} nomes de plantas foi criado.\")\n",
    "\n",
    "    # --- 3. Executar a busca automática ---\n",
    "    df_espacenet_enriquecido['texto_busca'] = (df_espacenet_enriquecido['title'] + ' ' + df_espacenet_enriquecido['abstract'])\n",
    "    df_espacenet_enriquecido['especies_encontradas_auto'] = df_espacenet_enriquecido['texto_busca'].str.findall(regex_pattern, flags=re.IGNORECASE)\n",
    "    print(\"[3] Busca automática por espécies concluída.\")\n",
    "\n",
    "    # --- 4. Exibir tabela de comparação ---\n",
    "    df_comparacao = pd.merge(\n",
    "        df_espacenet_enriquecido,\n",
    "        df_manual_padronizado, \n",
    "        on='publication_number',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    colunas_comparacao = ['publication_number', 'planta_levantada_manualmente', 'especies_encontradas_auto', 'title']\n",
    "    print(\"\\n--- Tabela de Comparação (Manual vs. Automático) ---\")\n",
    "    display(df_comparacao[\n",
    "        (df_comparacao['planta_levantada_manualmente'].notna()) | \n",
    "        (df_comparacao['especies_encontradas_auto'].apply(len) > 0)\n",
    "    ][colunas_comparacao].head(10))\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"ERRO: Um dos DataFrames necessários não foi encontrado. Certifique-se de que todas as células anteriores foram executadas. Detalhe: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf905642",
   "metadata": {},
   "source": [
    "# 3.8: Construindo o Modelo Final (Tabela Fato e Ponte de Espécies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "710c7595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Célula 8: Finalizando o modelo de dados da Espacenet (com pontes de datas) ---\n",
      "\n",
      "[1] Conectando patentes com a dimensão mestre de espécies...\n",
      "Tabela ponte 'pon_patente_especie' criada.\n",
      "\n",
      "[2] Criando tabelas ponte para os anos das colunas de data...\n",
      "Tabela ponte 'pon_patente_ano_prioridade' criada.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US2018206423A1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US10781458B2,US2020010514A1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US2010292280A1</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JP2001122732A</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US2010119627A1,US8329228B2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            publication_number   ano\n",
       "0               US2018206423A1  2017\n",
       "1  US10781458B2,US2020010514A1  2014\n",
       "2               US2010292280A1  2007\n",
       "3                JP2001122732A  1999\n",
       "4   US2010119627A1,US8329228B2  2006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela ponte 'pon_patente_ano_publicacao' criada.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US2018206423A1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US2010292280A1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JP2001122732A</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JPH10139680A</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JP2001055318A</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_number   ano\n",
       "0     US2018206423A1  2018\n",
       "2     US2010292280A1  2010\n",
       "3      JP2001122732A  2001\n",
       "6       JPH10139680A  1998\n",
       "7      JP2001055318A  2001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela ponte 'pon_patente_ano_primeira_publicacao' criada.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US2018206423A1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US10781458B2,US2020010514A1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US2010292280A1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JP2001122732A</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US2010119627A1,US8329228B2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            publication_number   ano\n",
       "0               US2018206423A1  2018\n",
       "1  US10781458B2,US2020010514A1  2016\n",
       "2               US2010292280A1  2008\n",
       "3                JP2001122732A  2001\n",
       "4   US2010119627A1,US8329228B2  2008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] Criando a tabela fato final 'fato_patentes_espacenet'...\n",
      "Tabela 'fato_patentes_espacenet' finalizada:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_number</th>\n",
       "      <th>family_number</th>\n",
       "      <th>especies_encontradas_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MARINE BIOMASS REACTOR AND METHODS RELATED THE...</td>\n",
       "      <td>US2018206423A1</td>\n",
       "      <td>61189536</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>INSECTICIDAL PROTEINS AND METHODS FOR THEIR USE</td>\n",
       "      <td>US10781458B2,US2020010514A1</td>\n",
       "      <td>54396965</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ANTI-PYRETIC VASODILATORS</td>\n",
       "      <td>US2010292280A1</td>\n",
       "      <td>39864457</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>COSMETIC COMPOSITION CONTAINING MOISTURIZING P...</td>\n",
       "      <td>JP2001122732A</td>\n",
       "      <td>17922236</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>SPECIAL EXTRACT AND USE THEREOF FOR INHIBITING...</td>\n",
       "      <td>US2010119627A1,US8329228B2</td>\n",
       "      <td>38121795</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   1  MARINE BIOMASS REACTOR AND METHODS RELATED THE...   \n",
       "1   2    INSECTICIDAL PROTEINS AND METHODS FOR THEIR USE   \n",
       "2   1                          ANTI-PYRETIC VASODILATORS   \n",
       "3   2  COSMETIC COMPOSITION CONTAINING MOISTURIZING P...   \n",
       "4   3  SPECIAL EXTRACT AND USE THEREOF FOR INHIBITING...   \n",
       "\n",
       "            publication_number  family_number especies_encontradas_auto  \n",
       "0               US2018206423A1       61189536                        []  \n",
       "1  US10781458B2,US2020010514A1       54396965                        []  \n",
       "2               US2010292280A1       39864457                        []  \n",
       "3                JP2001122732A       17922236                        []  \n",
       "4   US2010119627A1,US8329228B2       38121795                        []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Célula 8: Finalizando o modelo de dados da Espacenet (com pontes de datas) ---\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Conectar com a Dimensão Mestre de Espécies (lógica inalterada) ---\n",
    "    print(\"\\n[1] Conectando patentes com a dimensão mestre de espécies...\")\n",
    "    caminho_dim_especies = Path('../../data/processed/dim_especies_mestre.csv')\n",
    "    dim_especies_mestre = pd.read_csv(caminho_dim_especies)\n",
    "    lista_de_plantas = dim_especies_mestre['nome_cientifico'].dropna().unique().tolist()\n",
    "    regex_pattern = r'\\b(' + '|'.join(re.escape(nome) for nome in lista_de_plantas) + r')\\b'\n",
    "    \n",
    "    df_espacenet_enriquecido['especies_encontradas'] = df_espacenet_enriquecido['title'].str.findall(regex_pattern, flags=re.IGNORECASE)\n",
    "    \n",
    "    df_com_especies = df_espacenet_enriquecido[df_espacenet_enriquecido['especies_encontradas'].apply(len) > 0]\n",
    "    pon_patente_especie_temp = df_com_especies[['publication_number', 'especies_encontradas']].explode('especies_encontradas')\n",
    "    pon_patente_especie_temp.rename(columns={'especies_encontradas': 'nome_cientifico'}, inplace=True)\n",
    "    \n",
    "    pon_patente_especie = pd.merge(\n",
    "        pon_patente_especie_temp, dim_especies_mestre,\n",
    "        on='nome_cientifico', how='left'\n",
    "    )[['publication_number', 'especie_id']].drop_duplicates()\n",
    "    print(\"Tabela ponte 'pon_patente_especie' criada.\")\n",
    "\n",
    "    # --- 2. Criar Pontes para os Anos das Datas ---\n",
    "    print(\"\\n[2] Criando tabelas ponte para os anos das colunas de data...\")\n",
    "    colunas_de_data = {\n",
    "        'earliest_priority': 'ano_prioridade',\n",
    "        'publication_date': 'ano_publicacao',\n",
    "        'earliest_publication': 'ano_primeira_publicacao'\n",
    "    }\n",
    "    \n",
    "    tabelas_ponte_data = {} \n",
    "\n",
    "    for col_original, nome_ponte in colunas_de_data.items():\n",
    "        if col_original in df_espacenet_enriquecido.columns:\n",
    "            df_data_trab = df_espacenet_enriquecido[['publication_number', col_original]].copy()\n",
    "            df_data_trab.dropna(subset=[col_original], inplace=True)\n",
    "            \n",
    "            # CORREÇÃO: Garante que a coluna é do tipo string antes de usar .str.split()\n",
    "            df_data_trab[col_original] = df_data_trab[col_original].astype(str)\n",
    "            \n",
    "            # Divide a string por vírgula e explode\n",
    "            df_data_trab[col_original] = df_data_trab[col_original].str.split(',')\n",
    "            df_data_explodido = df_data_trab.explode(col_original)\n",
    "            \n",
    "            # Extrai o ano de cada data individual\n",
    "            df_data_explodido['ano'] = pd.to_datetime(df_data_explodido[col_original], errors='coerce').dt.year\n",
    "            df_data_explodido.dropna(subset=['ano'], inplace=True)\n",
    "            df_data_explodido['ano'] = df_data_explodido['ano'].astype(int)\n",
    "\n",
    "            # Cria a tabela ponte\n",
    "            ponte_df = df_data_explodido[['publication_number', 'ano']].drop_duplicates()\n",
    "            tabelas_ponte_data[f'pon_patente_{nome_ponte}'] = ponte_df\n",
    "            \n",
    "            print(f\"Tabela ponte 'pon_patente_{nome_ponte}' criada.\")\n",
    "            display(ponte_df.head())\n",
    "\n",
    "    # --- 3. Criar a Tabela Fato Final ---\n",
    "    print(\"\\n[3] Criando a tabela fato final 'fato_patentes_espacenet'...\")\n",
    "    \n",
    "    colunas_para_remover = [\n",
    "        'inventors', 'applicants', 'ipc', 'cpc', \n",
    "        'especies_encontradas', 'texto_busca', 'abstract',\n",
    "        'earliest_priority', 'publication_date', 'earliest_publication'\n",
    "    ]\n",
    "    colunas_existentes_para_remover = [col for col in colunas_para_remover if col in df_espacenet_enriquecido.columns]\n",
    "    \n",
    "    fato_patentes_espacenet = df_espacenet_enriquecido.drop(columns=colunas_existentes_para_remover)\n",
    "\n",
    "    print(\"Tabela 'fato_patentes_espacenet' finalizada:\")\n",
    "    display(fato_patentes_espacenet.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado. Detalhe: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1df0b8",
   "metadata": {},
   "source": [
    "# 3.9: Salvando Todas as Tabelas do Modelo Espacenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d679332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Célula 9: Salvando os resultados do modelo dimensional da Espacenet ---\n",
      "[1] Diretório de saída '../../data/processed/espacenet' está pronto.\n",
      "\n",
      "[2] Salvando arquivos CSV...\n",
      " -> Arquivo salvo: fato_patentes_espacenet.csv\n",
      " -> Arquivo salvo: dim_parties.csv\n",
      " -> Arquivo salvo: dim_country.csv\n",
      " -> Arquivo salvo: dim_ipc.csv\n",
      " -> Arquivo salvo: pon_patente_party.csv\n",
      " -> Arquivo salvo: pon_patente_country.csv\n",
      " -> Arquivo salvo: pon_patente_ipc.csv\n",
      " -> Arquivo salvo: pon_patente_especie.csv\n",
      " -> Arquivo salvo: pon_patente_ano_prioridade.csv\n",
      " -> Arquivo salvo: pon_patente_ano_publicacao.csv\n",
      " -> Arquivo salvo: pon_patente_ano_primeira_publicacao.csv\n",
      "\n",
      "--- Processo de salvamento concluído! ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Célula 9: Salvando os resultados do modelo dimensional da Espacenet ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Definir o caminho da pasta de saída\n",
    "    caminho_saida = Path('../../data/processed/espacenet')\n",
    "    \n",
    "    # Cria a pasta de saída, se ela não existir\n",
    "    caminho_saida.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"[1] Diretório de saída '{caminho_saida}' está pronto.\")\n",
    "\n",
    "    # 2. Criar um dicionário com todas as tabelas a serem salvas\n",
    "    tabelas_para_salvar = {\n",
    "        # Tabela Fato\n",
    "        \"fato_patentes_espacenet\": fato_patentes_espacenet,\n",
    "        \n",
    "        # Dimensões\n",
    "        \"dim_parties\": dim_parties,\n",
    "        \"dim_country\": dim_country,\n",
    "        \"dim_ipc\": dim_ipc,\n",
    "        \n",
    "        # Tabelas Ponte\n",
    "        \"pon_patente_party\": pon_patente_party,\n",
    "        \"pon_patente_country\": pon_patente_country,\n",
    "        \"pon_patente_ipc\": pon_patente_ipc,\n",
    "        \"pon_patente_especie\": pon_patente_especie\n",
    "    }\n",
    "    \n",
    "    # Adiciona as tabelas ponte de datas ao dicionário\n",
    "    # A variável 'tabelas_ponte_data' foi criada na Célula 8\n",
    "    if 'tabelas_ponte_data' in locals():\n",
    "        tabelas_para_salvar.update(tabelas_ponte_data)\n",
    "\n",
    "    # 3. Loop para salvar cada tabela\n",
    "    print(\"\\n[2] Salvando arquivos CSV...\")\n",
    "    for nome_arquivo, df_tabela in tabelas_para_salvar.items():\n",
    "        if df_tabela is not None:\n",
    "            caminho_completo = caminho_saida / f\"{nome_arquivo}.csv\"\n",
    "            df_tabela.to_csv(caminho_completo, index=False)\n",
    "            print(f\" -> Arquivo salvo: {nome_arquivo}.csv\")\n",
    "        else:\n",
    "            print(f\" -> Aviso: DataFrame para '{nome_arquivo}' não foi gerado e não foi salvo.\")\n",
    "            \n",
    "    print(\"\\n--- Processo de salvamento concluído! ---\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"ERRO: Um dos DataFrames necessários não foi encontrado. Certifique-se de que todas as células anteriores foram executadas. Detalhe: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
