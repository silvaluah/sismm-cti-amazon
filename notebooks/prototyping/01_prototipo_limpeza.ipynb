{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e069f42",
   "metadata": {},
   "source": [
    "# BLOCO 1 - PROTOTIPAGEM DE DADOS FONTE SCOPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e2046",
   "metadata": {},
   "source": [
    "\n",
    "# 1.1: Importação de bibliotecas e encontro de arquivos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f99621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Passo 1: Localizando arquivos de dados ---\n",
      "Arquivos localizados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "print(\"--- Passo 1: Localizando arquivos de dados ---\")\n",
    "# Caminho corrigido para o seu ambiente\n",
    "caminho_base = Path('../../data/raw')\n",
    "dados_por_fonte = {}\n",
    "\n",
    "if not caminho_base.is_dir():\n",
    "    print(f\"ERRO: Diretório '{caminho_base.resolve()}' não encontrado.\")\n",
    "else:\n",
    "    for fonte_path in caminho_base.iterdir():\n",
    "        if fonte_path.is_dir():\n",
    "            nome_da_fonte = fonte_path.name\n",
    "            arquivos = list(fonte_path.glob('*.csv')) + list(fonte_path.glob('*.txt'))\n",
    "            dados_por_fonte[nome_da_fonte] = arquivos\n",
    "    print(\"Arquivos localizados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c9bbb",
   "metadata": {},
   "source": [
    "# 1.2: Carregamento e consolidação os dados da fonte \"Scopus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2718ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Passo 2: Consolidando dados da fonte 'scopus_input' ---\n",
      "Dados da Scopus consolidados. Total de 800 linhas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Passo 2: Consolidando dados da fonte 'scopus_input' ---\")\n",
    "lista_dataframes_scopus = []\n",
    "# O nome da pasta na sua saída foi \"scopus_input\", vamos usá-lo\n",
    "arquivos_scopus = dados_por_fonte.get('scopus_input', [])\n",
    "\n",
    "if not arquivos_scopus:\n",
    "    print(\"ERRO: Nenhum arquivo encontrado para a fonte 'scopus_input'.\")\n",
    "else:\n",
    "    for arquivo_path in arquivos_scopus:\n",
    "        if arquivo_path.suffix == '.csv':\n",
    "            df_temp = pd.read_csv(arquivo_path)\n",
    "            lista_dataframes_scopus.append(df_temp)\n",
    "            \n",
    "    if not lista_dataframes_scopus:\n",
    "        print(\"ERRO: Nenhum arquivo CSV foi carregado da fonte Scopus.\")\n",
    "    else:\n",
    "        df_scopus = pd.concat(lista_dataframes_scopus, ignore_index=True)\n",
    "        print(f\"Dados da Scopus consolidados. Total de {len(df_scopus)} linhas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d30c0e5",
   "metadata": {},
   "source": [
    "# 1.3 Padronização dos nomes das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f609280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Passo 3: Padronizando nomes das colunas ---\n",
      "Nomes originais: ['Authors', 'Author full names', 'Author(s) ID', 'Title', 'Year', 'Source title', 'Volume', 'Issue', 'Art. No.', 'Page start', 'Page end', 'Page count', 'Cited by', 'DOI', 'Link', 'Affiliations', 'Authors with affiliations', 'Abstract', 'Author Keywords', 'Index Keywords', 'Molecular Sequence Numbers', 'Chemicals/CAS', 'Tradenames', 'Manufacturers', 'Funding Details', 'Funding Texts', 'References', 'Correspondence Address', 'Editors', 'Publisher', 'Sponsors', 'Conference name', 'Conference date', 'Conference location', 'Conference code', 'ISSN', 'ISBN', 'CODEN', 'PubMed ID', 'Language of Original Document', 'Abbreviated Source Title', 'Document Type', 'Publication Stage', 'Open Access', 'Source', 'EID', 'Funding Text 1', 'Funding Text 2']\n",
      "Nomes padronizados: ['authors', 'author_full_names', 'authors_id', 'title', 'year', 'source_title', 'volume', 'issue', 'art_no', 'page_start', 'page_end', 'page_count', 'cited_by', 'doi', 'link', 'affiliations', 'authors_with_affiliations', 'abstract', 'author_keywords', 'index_keywords', 'molecular_sequence_numbers', 'chemicalscas', 'tradenames', 'manufacturers', 'funding_details', 'funding_texts', 'references', 'correspondence_address', 'editors', 'publisher', 'sponsors', 'conference_name', 'conference_date', 'conference_location', 'conference_code', 'issn', 'isbn', 'coden', 'pubmed_id', 'language_of_original_document', 'abbreviated_source_title', 'document_type', 'publication_stage', 'open_access', 'source', 'eid', 'funding_text_1', 'funding_text_2']\n",
      "\n",
      "--- Processo concluído! DataFrame 'df_scopus' está pronto para a próxima etapa. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>author_full_names</th>\n",
       "      <th>authors_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>source_title</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>art_no</th>\n",
       "      <th>page_start</th>\n",
       "      <th>...</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>language_of_original_document</th>\n",
       "      <th>abbreviated_source_title</th>\n",
       "      <th>document_type</th>\n",
       "      <th>publication_stage</th>\n",
       "      <th>open_access</th>\n",
       "      <th>source</th>\n",
       "      <th>eid</th>\n",
       "      <th>funding_text_1</th>\n",
       "      <th>funding_text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do Nascimento C.S.; de Almeida Cruz I.; do Nas...</td>\n",
       "      <td>do Nascimento, Cristiano Souza (57212932024); ...</td>\n",
       "      <td>57212932024; 58355365500; 26028309100; 5595411...</td>\n",
       "      <td>Technological properties of wood from small di...</td>\n",
       "      <td>2023</td>\n",
       "      <td>European Journal of Forest Research</td>\n",
       "      <td>142.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Eur. J. For. Res.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85162981044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da Silva A.S.O.; de Carvalho J.O.P.; Dionisio ...</td>\n",
       "      <td>da Silva, Antonia Sandra Oliveira (58119830300...</td>\n",
       "      <td>58119830300; 7102474765; 57189244151; 36928208...</td>\n",
       "      <td>Structure of Eschweilera amazonica R. Knuth (m...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Scientia Forestalis/Forest Sciences</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e3920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>Sci Forest</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access; Gold Open Access</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85149013333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daly D.C.</td>\n",
       "      <td>Daly, Douglas C. (7102740855)</td>\n",
       "      <td>7102740855</td>\n",
       "      <td>A rare new species of Protium from Rondônia, B...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Brittonia</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Brittonia</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85160833451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Londoño-Echeverri Y.; Trujillo-López A.M.; Pér...</td>\n",
       "      <td>Londoño-Echeverri, Yeison (57221612640); Truji...</td>\n",
       "      <td>57221612640; 57221607661; 58531148900</td>\n",
       "      <td>A new species of Conchocarpus and first record...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Phytotaxa</td>\n",
       "      <td>601.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Phytotaxa</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85167577291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corrêa P.G.; Moura L.G.S.; Amaral A.C.F.; do A...</td>\n",
       "      <td>Corrêa, Pollyane Gomes (58001294800); Moura, L...</td>\n",
       "      <td>58001294800; 58002168600; 7005934688; 57209362...</td>\n",
       "      <td>Chemical and nutritional characterization of A...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Food Research International</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36596195.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Food Res. Int.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85143804200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "0  do Nascimento C.S.; de Almeida Cruz I.; do Nas...   \n",
       "1  da Silva A.S.O.; de Carvalho J.O.P.; Dionisio ...   \n",
       "2                                          Daly D.C.   \n",
       "3  Londoño-Echeverri Y.; Trujillo-López A.M.; Pér...   \n",
       "4  Corrêa P.G.; Moura L.G.S.; Amaral A.C.F.; do A...   \n",
       "\n",
       "                                   author_full_names  \\\n",
       "0  do Nascimento, Cristiano Souza (57212932024); ...   \n",
       "1  da Silva, Antonia Sandra Oliveira (58119830300...   \n",
       "2                      Daly, Douglas C. (7102740855)   \n",
       "3  Londoño-Echeverri, Yeison (57221612640); Truji...   \n",
       "4  Corrêa, Pollyane Gomes (58001294800); Moura, L...   \n",
       "\n",
       "                                          authors_id  \\\n",
       "0  57212932024; 58355365500; 26028309100; 5595411...   \n",
       "1  58119830300; 7102474765; 57189244151; 36928208...   \n",
       "2                                         7102740855   \n",
       "3              57221612640; 57221607661; 58531148900   \n",
       "4  58001294800; 58002168600; 7005934688; 57209362...   \n",
       "\n",
       "                                               title  year  \\\n",
       "0  Technological properties of wood from small di...  2023   \n",
       "1  Structure of Eschweilera amazonica R. Knuth (m...  2023   \n",
       "2  A rare new species of Protium from Rondônia, B...  2023   \n",
       "3  A new species of Conchocarpus and first record...  2023   \n",
       "4  Chemical and nutritional characterization of A...  2023   \n",
       "\n",
       "                          source_title  volume issue  art_no page_start  ...  \\\n",
       "0  European Journal of Forest Research   142.0     5     NaN       1225  ...   \n",
       "1  Scientia Forestalis/Forest Sciences    51.0   NaN   e3920        NaN  ...   \n",
       "2                            Brittonia    75.0     2     NaN        210  ...   \n",
       "3                            Phytotaxa   601.0     2     NaN        174  ...   \n",
       "4          Food Research International   163.0   NaN  112290        NaN  ...   \n",
       "\n",
       "    pubmed_id  language_of_original_document  abbreviated_source_title  \\\n",
       "0         NaN                        English         Eur. J. For. Res.   \n",
       "1         NaN                     Portuguese                Sci Forest   \n",
       "2         NaN                        English                 Brittonia   \n",
       "3         NaN                        English                 Phytotaxa   \n",
       "4  36596195.0                        English            Food Res. Int.   \n",
       "\n",
       "  document_type publication_stage                        open_access  source  \\\n",
       "0       Article             Final                                NaN  Scopus   \n",
       "1       Article             Final  All Open Access; Gold Open Access  Scopus   \n",
       "2       Article             Final                                NaN  Scopus   \n",
       "3       Article             Final                                NaN  Scopus   \n",
       "4       Article             Final                                NaN  Scopus   \n",
       "\n",
       "                  eid funding_text_1 funding_text_2  \n",
       "0  2-s2.0-85162981044            NaN            NaN  \n",
       "1  2-s2.0-85149013333            NaN            NaN  \n",
       "2  2-s2.0-85160833451            NaN            NaN  \n",
       "3  2-s2.0-85167577291            NaN            NaN  \n",
       "4  2-s2.0-85143804200            NaN            NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if 'df_scopus' in locals():\n",
    "    print(\"\\n--- Passo 3: Padronizando nomes das colunas ---\")\n",
    "    print(\"Nomes originais:\", df_scopus.columns.tolist())\n",
    "    \n",
    "    novas_colunas = []\n",
    "    for col in df_scopus.columns:\n",
    "        col_normalizada = unicodedata.normalize('NFKD', col).encode('ascii', 'ignore').decode('utf-8')\n",
    "        col_minuscula = col_normalizada.lower()\n",
    "        col_com_underscore = col_minuscula.replace(' ', '_').replace('-', '_')\n",
    "        col_final = re.sub(r'[^\\w_]', '', col_com_underscore)\n",
    "        novas_colunas.append(col_final)\n",
    "\n",
    "    df_scopus.columns = novas_colunas\n",
    "    print(\"Nomes padronizados:\", df_scopus.columns.tolist())\n",
    "    \n",
    "    print(\"\\n--- Processo concluído! DataFrame 'df_scopus' está pronto para a próxima etapa. ---\")\n",
    "    display(df_scopus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32183c",
   "metadata": {},
   "source": [
    "# 1.4: Diagnóstico de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ce3c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Célula 4: Analisando Valores Ausentes ---\n",
      "Relatório de Valores Ausentes (em ordem decrescente de %):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valores_ausentes</th>\n",
       "      <th>percentual_ausente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>editors</th>\n",
       "      <td>800</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <td>800</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conference_name</th>\n",
       "      <td>799</td>\n",
       "      <td>99.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sponsors</th>\n",
       "      <td>799</td>\n",
       "      <td>99.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conference_date</th>\n",
       "      <td>799</td>\n",
       "      <td>99.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conference_code</th>\n",
       "      <td>799</td>\n",
       "      <td>99.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conference_location</th>\n",
       "      <td>799</td>\n",
       "      <td>99.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manufacturers</th>\n",
       "      <td>798</td>\n",
       "      <td>99.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular_sequence_numbers</th>\n",
       "      <td>798</td>\n",
       "      <td>99.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tradenames</th>\n",
       "      <td>797</td>\n",
       "      <td>99.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funding_text_2</th>\n",
       "      <td>796</td>\n",
       "      <td>99.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funding_text_1</th>\n",
       "      <td>778</td>\n",
       "      <td>97.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art_no</th>\n",
       "      <td>696</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemicalscas</th>\n",
       "      <td>672</td>\n",
       "      <td>84.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubmed_id</th>\n",
       "      <td>671</td>\n",
       "      <td>83.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funding_texts</th>\n",
       "      <td>491</td>\n",
       "      <td>61.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funding_details</th>\n",
       "      <td>463</td>\n",
       "      <td>57.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_access</th>\n",
       "      <td>456</td>\n",
       "      <td>57.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coden</th>\n",
       "      <td>415</td>\n",
       "      <td>51.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_keywords</th>\n",
       "      <td>339</td>\n",
       "      <td>42.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <td>254</td>\n",
       "      <td>31.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correspondence_address</th>\n",
       "      <td>237</td>\n",
       "      <td>29.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page_count</th>\n",
       "      <td>141</td>\n",
       "      <td>17.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page_end</th>\n",
       "      <td>108</td>\n",
       "      <td>13.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page_start</th>\n",
       "      <td>106</td>\n",
       "      <td>13.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_keywords</th>\n",
       "      <td>99</td>\n",
       "      <td>12.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue</th>\n",
       "      <td>77</td>\n",
       "      <td>9.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doi</th>\n",
       "      <td>50</td>\n",
       "      <td>6.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_full_names</th>\n",
       "      <td>46</td>\n",
       "      <td>5.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>references</th>\n",
       "      <td>31</td>\n",
       "      <td>3.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>7</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authors_with_affiliations</th>\n",
       "      <td>6</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbreviated_source_title</th>\n",
       "      <td>6</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affiliations</th>\n",
       "      <td>6</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cited_by</th>\n",
       "      <td>5</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issn</th>\n",
       "      <td>2</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authors_id</th>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authors</th>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            valores_ausentes  percentual_ausente\n",
       "editors                                  800             100.000\n",
       "isbn                                     800             100.000\n",
       "conference_name                          799              99.875\n",
       "sponsors                                 799              99.875\n",
       "conference_date                          799              99.875\n",
       "conference_code                          799              99.875\n",
       "conference_location                      799              99.875\n",
       "manufacturers                            798              99.750\n",
       "molecular_sequence_numbers               798              99.750\n",
       "tradenames                               797              99.625\n",
       "funding_text_2                           796              99.500\n",
       "funding_text_1                           778              97.250\n",
       "art_no                                   696              87.000\n",
       "chemicalscas                             672              84.000\n",
       "pubmed_id                                671              83.875\n",
       "funding_texts                            491              61.375\n",
       "funding_details                          463              57.875\n",
       "open_access                              456              57.000\n",
       "coden                                    415              51.875\n",
       "index_keywords                           339              42.375\n",
       "publisher                                254              31.750\n",
       "correspondence_address                   237              29.625\n",
       "page_count                               141              17.625\n",
       "page_end                                 108              13.500\n",
       "page_start                               106              13.250\n",
       "author_keywords                           99              12.375\n",
       "issue                                     77               9.625\n",
       "doi                                       50               6.250\n",
       "author_full_names                         46               5.750\n",
       "references                                31               3.875\n",
       "volume                                     7               0.875\n",
       "authors_with_affiliations                  6               0.750\n",
       "abbreviated_source_title                   6               0.750\n",
       "affiliations                               6               0.750\n",
       "cited_by                                   5               0.625\n",
       "issn                                       2               0.250\n",
       "authors_id                                 1               0.125\n",
       "authors                                    1               0.125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Célula 4: Analisando Valores Ausentes ---\")\n",
    "if 'df_scopus' not in locals():\n",
    "    print(\"ERRO: O DataFrame 'df_scopus' não foi encontrado. Execute as células anteriores primeiro.\")\n",
    "else:\n",
    "    # Calcula o total de valores nulos por coluna\n",
    "    valores_ausentes = df_scopus.isnull().sum()\n",
    "    \n",
    "    # Calcula o percentual de valores nulos por coluna\n",
    "    percentual_ausente = (df_scopus.isnull().sum() / len(df_scopus)) * 100\n",
    "    \n",
    "    # Cria um novo DataFrame para apresentar o resultado de forma organizada\n",
    "    df_ausentes = pd.DataFrame({\n",
    "        'valores_ausentes': valores_ausentes,\n",
    "        'percentual_ausente': percentual_ausente\n",
    "    })\n",
    "    \n",
    "    # Filtra para mostrar apenas colunas que de fato têm valores ausentes\n",
    "    # e ordena para mostrar as mais problemáticas primeiro\n",
    "    df_ausentes = df_ausentes[df_ausentes['valores_ausentes'] > 0].sort_values(\n",
    "        by='percentual_ausente', ascending=False\n",
    "    )\n",
    "    \n",
    "    if df_ausentes.empty:\n",
    "        print(\"Ótima notícia! Não há valores ausentes no DataFrame.\")\n",
    "    else:\n",
    "        print(\"Relatório de Valores Ausentes (em ordem decrescente de %):\")\n",
    "        # Usamos display() para uma formatação de tabela mais bonita no notebook\n",
    "        display(df_ausentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c6317",
   "metadata": {},
   "source": [
    "# 1.5: Removendo colunas com mais de 60% de valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86022734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Célula 5: Removendo colunas com mais de 60% de valores ausentes ---\n",
      "Total de colunas a serem removidas: 16\n",
      "Colunas removidas: ['editors', 'isbn', 'conference_name', 'sponsors', 'conference_date', 'conference_code', 'conference_location', 'manufacturers', 'molecular_sequence_numbers', 'tradenames', 'funding_text_2', 'funding_text_1', 'art_no', 'chemicalscas', 'pubmed_id', 'funding_texts']\n",
      "\n",
      "DataFrame limpo! O número de colunas passou de 48 para 32.\n",
      "\n",
      "Informações do novo DataFrame 'df_scopus_limpo':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   authors                        799 non-null    object \n",
      " 1   author_full_names              754 non-null    object \n",
      " 2   authors_id                     799 non-null    object \n",
      " 3   title                          800 non-null    object \n",
      " 4   year                           800 non-null    int64  \n",
      " 5   source_title                   800 non-null    object \n",
      " 6   volume                         793 non-null    float64\n",
      " 7   issue                          723 non-null    object \n",
      " 8   page_start                     694 non-null    object \n",
      " 9   page_end                       692 non-null    object \n",
      " 10  page_count                     659 non-null    float64\n",
      " 11  cited_by                       795 non-null    float64\n",
      " 12  doi                            750 non-null    object \n",
      " 13  link                           800 non-null    object \n",
      " 14  affiliations                   794 non-null    object \n",
      " 15  authors_with_affiliations      794 non-null    object \n",
      " 16  abstract                       800 non-null    object \n",
      " 17  author_keywords                701 non-null    object \n",
      " 18  index_keywords                 461 non-null    object \n",
      " 19  funding_details                337 non-null    object \n",
      " 20  references                     769 non-null    object \n",
      " 21  correspondence_address         563 non-null    object \n",
      " 22  publisher                      546 non-null    object \n",
      " 23  issn                           798 non-null    object \n",
      " 24  coden                          385 non-null    object \n",
      " 25  language_of_original_document  800 non-null    object \n",
      " 26  abbreviated_source_title       794 non-null    object \n",
      " 27  document_type                  800 non-null    object \n",
      " 28  publication_stage              800 non-null    object \n",
      " 29  open_access                    344 non-null    object \n",
      " 30  source                         800 non-null    object \n",
      " 31  eid                            800 non-null    object \n",
      "dtypes: float64(3), int64(1), object(28)\n",
      "memory usage: 200.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Célula 5: Removendo colunas com mais de 60% de valores ausentes ---\")\n",
    "\n",
    "if 'df_scopus' not in locals() or 'df_ausentes' not in locals():\n",
    "    print(\"ERRO: Certifique-se de que as Células 2, 3 e 4 foram executadas com sucesso.\")\n",
    "else:\n",
    "    # Define o limiar de percentual para remoção (AJUSTADO CONFORME SOLICITADO)\n",
    "    limiar_percentual = 60.0\n",
    "    \n",
    "    # Identifica as colunas a serem removidas com base no relatório da Célula 4\n",
    "    colunas_para_remover = df_ausentes[df_ausentes['percentual_ausente'] > limiar_percentual].index.tolist()\n",
    "    \n",
    "    if not colunas_para_remover:\n",
    "        print(\"Nenhuma coluna ultrapassou o limiar de 60% de ausência. Nenhuma coluna foi removida.\")\n",
    "        # Se nenhuma coluna for removida, o df_scopus_limpo é uma cópia do original\n",
    "        df_scopus_limpo = df_scopus.copy()\n",
    "    else:\n",
    "        print(f\"Total de colunas a serem removidas: {len(colunas_para_remover)}\")\n",
    "        print(\"Colunas removidas:\", colunas_para_remover)\n",
    "        \n",
    "        # Cria um novo DataFrame sem as colunas indesejadas\n",
    "        df_scopus_limpo = df_scopus.drop(columns=colunas_para_remover)\n",
    "        \n",
    "        print(f\"\\nDataFrame limpo! O número de colunas passou de {len(df_scopus.columns)} para {len(df_scopus_limpo.columns)}.\")\n",
    "\n",
    "    # Exibe as informações do novo DataFrame para vermos o resultado\n",
    "    print(\"\\nInformações do novo DataFrame 'df_scopus_limpo':\")\n",
    "    df_scopus_limpo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa13d58",
   "metadata": {},
   "source": [
    "# 1.6: Imputação (Preenchimento) de Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3e64d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Célula 6: Preenchendo os valores ausentes restantes ---\n",
      "Valores ausentes ANTES da imputação:\n",
      "funding_details    463\n",
      "open_access        456\n",
      "coden              415\n",
      "index_keywords     339\n",
      "publisher          254\n",
      "dtype: int64\n",
      "\n",
      "Imputação concluída!\n",
      "\n",
      "Informações do DataFrame 'df_scopus_limpo' APÓS a imputação:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   authors                        800 non-null    object \n",
      " 1   author_full_names              800 non-null    object \n",
      " 2   authors_id                     800 non-null    object \n",
      " 3   title                          800 non-null    object \n",
      " 4   year                           800 non-null    int64  \n",
      " 5   source_title                   800 non-null    object \n",
      " 6   volume                         800 non-null    float64\n",
      " 7   issue                          800 non-null    object \n",
      " 8   page_start                     800 non-null    object \n",
      " 9   page_end                       800 non-null    object \n",
      " 10  page_count                     800 non-null    float64\n",
      " 11  cited_by                       800 non-null    float64\n",
      " 12  doi                            800 non-null    object \n",
      " 13  link                           800 non-null    object \n",
      " 14  affiliations                   800 non-null    object \n",
      " 15  authors_with_affiliations      800 non-null    object \n",
      " 16  abstract                       800 non-null    object \n",
      " 17  author_keywords                800 non-null    object \n",
      " 18  index_keywords                 800 non-null    object \n",
      " 19  funding_details                800 non-null    object \n",
      " 20  references                     800 non-null    object \n",
      " 21  correspondence_address         800 non-null    object \n",
      " 22  publisher                      800 non-null    object \n",
      " 23  issn                           800 non-null    object \n",
      " 24  coden                          800 non-null    object \n",
      " 25  language_of_original_document  800 non-null    object \n",
      " 26  abbreviated_source_title       800 non-null    object \n",
      " 27  document_type                  800 non-null    object \n",
      " 28  publication_stage              800 non-null    object \n",
      " 29  open_access                    800 non-null    object \n",
      " 30  source                         800 non-null    object \n",
      " 31  eid                            800 non-null    object \n",
      "dtypes: float64(3), int64(1), object(28)\n",
      "memory usage: 200.1+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28237/2039522170.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna('nao_informado', inplace=True)\n",
      "/tmp/ipykernel_28237/2039522170.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Célula 6: Preenchendo os valores ausentes restantes ---\")\n",
    "\n",
    "if 'df_scopus_limpo' not in locals():\n",
    "    print(\"ERRO: O DataFrame 'df_scopus_limpo' não foi encontrado. Execute a Célula 5 primeiro.\")\n",
    "else:\n",
    "    # Mostra um resumo dos dados faltantes ANTES do preenchimento\n",
    "    print(\"Valores ausentes ANTES da imputação:\")\n",
    "    print(df_scopus_limpo.isnull().sum().sort_values(ascending=False).head())\n",
    "\n",
    "    # Itera sobre cada coluna do DataFrame para aplicar o preenchimento\n",
    "    for coluna in df_scopus_limpo.columns:\n",
    "        # Verifica se a coluna tem algum valor nulo para otimizar o processo\n",
    "        if df_scopus_limpo[coluna].isnull().any():\n",
    "            # Se a coluna for do tipo 'object' (texto), preenche com 'nao_informado'\n",
    "            if df_scopus_limpo[coluna].dtype == 'object':\n",
    "                df_scopus_limpo[coluna].fillna('nao_informado', inplace=True)\n",
    "            # Se for numérica, preenche com 0\n",
    "            else:\n",
    "                df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
    "\n",
    "    print(\"\\nImputação concluída!\")\n",
    "    \n",
    "    # Executa o .info() para PROVAR que não há mais valores nulos\n",
    "    # A contagem de \"Non-Null Count\" deve ser igual para todas as colunas\n",
    "    print(\"\\nInformações do DataFrame 'df_scopus_limpo' APÓS a imputação:\")\n",
    "    df_scopus_limpo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c10701",
   "metadata": {},
   "source": [
    "# 1.7: Correção dos Tipos de Dados (Dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697d1a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Célula 7: Corrigindo os tipos de dados (Dtypes) ---\n",
      "Tentando converter as seguintes colunas para o tipo numérico: ['year', 'volume', 'issue', 'page_start', 'page_end', 'page_count', 'cited_by']\n",
      "\n",
      "Conversão de tipos de dados concluída!\n",
      "\n",
      "Informações do DataFrame 'df_scopus_limpo' APÓS a correção de tipos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   authors                        800 non-null    object\n",
      " 1   author_full_names              800 non-null    object\n",
      " 2   authors_id                     800 non-null    object\n",
      " 3   title                          800 non-null    object\n",
      " 4   year                           800 non-null    int64 \n",
      " 5   source_title                   800 non-null    object\n",
      " 6   volume                         800 non-null    int64 \n",
      " 7   issue                          800 non-null    int64 \n",
      " 8   page_start                     800 non-null    int64 \n",
      " 9   page_end                       800 non-null    int64 \n",
      " 10  page_count                     800 non-null    int64 \n",
      " 11  cited_by                       800 non-null    int64 \n",
      " 12  doi                            800 non-null    object\n",
      " 13  link                           800 non-null    object\n",
      " 14  affiliations                   800 non-null    object\n",
      " 15  authors_with_affiliations      800 non-null    object\n",
      " 16  abstract                       800 non-null    object\n",
      " 17  author_keywords                800 non-null    object\n",
      " 18  index_keywords                 800 non-null    object\n",
      " 19  funding_details                800 non-null    object\n",
      " 20  references                     800 non-null    object\n",
      " 21  correspondence_address         800 non-null    object\n",
      " 22  publisher                      800 non-null    object\n",
      " 23  issn                           800 non-null    object\n",
      " 24  coden                          800 non-null    object\n",
      " 25  language_of_original_document  800 non-null    object\n",
      " 26  abbreviated_source_title       800 non-null    object\n",
      " 27  document_type                  800 non-null    object\n",
      " 28  publication_stage              800 non-null    object\n",
      " 29  open_access                    800 non-null    object\n",
      " 30  source                         800 non-null    object\n",
      " 31  eid                            800 non-null    object\n",
      "dtypes: int64(7), object(25)\n",
      "memory usage: 200.1+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28237/1173396441.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_28237/1173396441.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_28237/1173396441.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_28237/1173396441.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_28237/1173396441.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_28237/1173396441.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_28237/1173396441.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_scopus_limpo[coluna].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Célula 7: Corrigindo os tipos de dados (Dtypes) ---\")\n",
    "\n",
    "if 'df_scopus_limpo' not in locals():\n",
    "    print(\"ERRO: O DataFrame 'df_scopus_limpo' não foi encontrado. Execute as células anteriores primeiro.\")\n",
    "else:\n",
    "    # Lista de colunas que deveriam ser numéricas.\n",
    "    # Revise e ajuste esta lista conforme necessário para seus dados.\n",
    "    colunas_para_converter = [\n",
    "        'year', \n",
    "        'volume', \n",
    "        'issue', \n",
    "        'page_start', \n",
    "        'page_end', \n",
    "        'page_count', \n",
    "        'cited_by'\n",
    "    ]\n",
    "\n",
    "    print(\"Tentando converter as seguintes colunas para o tipo numérico:\", colunas_para_converter)\n",
    "\n",
    "    for coluna in colunas_para_converter:\n",
    "        # Verifica se a coluna existe no DataFrame antes de tentar converter\n",
    "        if coluna in df_scopus_limpo.columns:\n",
    "            # Converte para numérico. errors='coerce' transforma falhas em NaN.\n",
    "            df_scopus_limpo[coluna] = pd.to_numeric(df_scopus_limpo[coluna], errors='coerce')\n",
    "            # Preenche quaisquer NaNs que possam ter sido criados na conversão\n",
    "            df_scopus_limpo[coluna].fillna(0, inplace=True)\n",
    "            # Converte a coluna para o tipo inteiro para economizar memória e ser mais preciso\n",
    "            df_scopus_limpo[coluna] = df_scopus_limpo[coluna].astype(int)\n",
    "        else:\n",
    "            print(f\"Aviso: A coluna '{coluna}' não foi encontrada no DataFrame e foi ignorada.\")\n",
    "\n",
    "    print(\"\\nConversão de tipos de dados concluída!\")\n",
    "    \n",
    "    # Exibe as informações do DataFrame para vermos as mudanças nos Dtypes\n",
    "    print(\"\\nInformações do DataFrame 'df_scopus_limpo' APÓS a correção de tipos:\")\n",
    "    df_scopus_limpo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a31534",
   "metadata": {},
   "source": [
    "# 1.8: Verificação e Remoção de Duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d05fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Célula 8: Verificando e Removendo Duplicatas ---\n",
      "Foram encontradas 0 linhas duplicadas.\n",
      "Nenhuma linha duplicada encontrada. O DataFrame já está limpo.\n",
      "\n",
      "--- Processo de Limpeza e Padronização da Fonte Scopus CONCLUÍDO! ---\n",
      "\n",
      "Informações do DataFrame final 'df_scopus_final':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   authors                        800 non-null    object\n",
      " 1   author_full_names              800 non-null    object\n",
      " 2   authors_id                     800 non-null    object\n",
      " 3   title                          800 non-null    object\n",
      " 4   year                           800 non-null    int64 \n",
      " 5   source_title                   800 non-null    object\n",
      " 6   volume                         800 non-null    int64 \n",
      " 7   issue                          800 non-null    int64 \n",
      " 8   page_start                     800 non-null    int64 \n",
      " 9   page_end                       800 non-null    int64 \n",
      " 10  page_count                     800 non-null    int64 \n",
      " 11  cited_by                       800 non-null    int64 \n",
      " 12  doi                            800 non-null    object\n",
      " 13  link                           800 non-null    object\n",
      " 14  affiliations                   800 non-null    object\n",
      " 15  authors_with_affiliations      800 non-null    object\n",
      " 16  abstract                       800 non-null    object\n",
      " 17  author_keywords                800 non-null    object\n",
      " 18  index_keywords                 800 non-null    object\n",
      " 19  funding_details                800 non-null    object\n",
      " 20  references                     800 non-null    object\n",
      " 21  correspondence_address         800 non-null    object\n",
      " 22  publisher                      800 non-null    object\n",
      " 23  issn                           800 non-null    object\n",
      " 24  coden                          800 non-null    object\n",
      " 25  language_of_original_document  800 non-null    object\n",
      " 26  abbreviated_source_title       800 non-null    object\n",
      " 27  document_type                  800 non-null    object\n",
      " 28  publication_stage              800 non-null    object\n",
      " 29  open_access                    800 non-null    object\n",
      " 30  source                         800 non-null    object\n",
      " 31  eid                            800 non-null    object\n",
      "dtypes: int64(7), object(25)\n",
      "memory usage: 200.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Célula 8: Verificando e Removendo Duplicatas ---\")\n",
    "\n",
    "if 'df_scopus_limpo' not in locals():\n",
    "    print(\"ERRO: O DataFrame 'df_scopus_limpo' não foi encontrado. Execute as células anteriores primeiro.\")\n",
    "else:\n",
    "    # 1. Verifica a quantidade de linhas duplicadas\n",
    "    num_duplicatas = df_scopus_limpo.duplicated().sum()\n",
    "    print(f\"Foram encontradas {num_duplicatas} linhas duplicadas.\")\n",
    "\n",
    "    # 2. Remove as duplicatas, se existirem\n",
    "    if num_duplicatas > 0:\n",
    "        linhas_antes = len(df_scopus_limpo)\n",
    "        # keep='first' (padrão) mantém a primeira ocorrência e remove as subsequentes\n",
    "        df_scopus_final = df_scopus_limpo.drop_duplicates(keep='first')\n",
    "        linhas_depois = len(df_scopus_final)\n",
    "        print(f\"{num_duplicatas} linhas duplicadas foram removidas.\")\n",
    "        print(f\"O número total de linhas passou de {linhas_antes} para {linhas_depois}.\")\n",
    "    else:\n",
    "        print(\"Nenhuma linha duplicada encontrada. O DataFrame já está limpo.\")\n",
    "        # Se não há duplicatas, o DataFrame final é uma cópia do anterior\n",
    "        df_scopus_final = df_scopus_limpo.copy()\n",
    "\n",
    "    print(\"\\n--- Processo de Limpeza e Padronização da Fonte Scopus CONCLUÍDO! ---\")\n",
    "    print(\"\\nInformações do DataFrame final 'df_scopus_final':\")\n",
    "    df_scopus_final.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
